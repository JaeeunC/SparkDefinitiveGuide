{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Scala\n",
    "val spark2 = spark // 책과는 다르게 \n",
    "import spark2.implicits._\n",
    "\n",
    "case class Flight(DEST_COUNTRY_NAME: String,\n",
    "                  ORIGIN_COUNTRY_NAME: String,\n",
    "                  count: BigInt)\n",
    "val flightsDF = spark2.read\n",
    "  .parquet(\"./data/flight-data/parquet/2010-summary.parquet/\")\n",
    "val flights = flightsDF.as[Flight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights\n",
    "    .filter(flight_row => flight_row.ORIGIN_COUNTRY_NAME != \"Canada\")\n",
    "    .map(flight_row => flight_row)\n",
    "    .take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights\n",
    "    .take(5)\n",
    "    .filter(flight_row => flight_row.ORIGIN_COUNTRY_NAME != \"Canada\")\n",
    "    .map(fr => Flight(fr.DEST_COUNTRY_NAME, fr.ORIGIN_COUNTRY_NAME, fr.count + 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 구조적 스트리밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val staticDataFrame = spark2.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(\"./data/retail-data/by-day/*.csv\")\n",
    "\n",
    "staticDataFrame.createOrReplaceTempView(\"retail_data\")\n",
    "val staticSchema = staticDataFrame.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{window, col}\n",
    "\n",
    "staticDataFrame\n",
    "    .selectExpr(\n",
    "        \"CustomerId\",\n",
    "        \"(UnitPrice * Quantity) as total_cost\",\n",
    "        \"InvoiceDate\")\n",
    "    .groupBy(\n",
    "        col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\"))\n",
    "    .sum(\"total_cost\")\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partition\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val streamingDataFrame = spark.readStream\n",
    "    .schema(staticSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 20)\n",
    "    .format(\"csv\")\n",
    "    .option(\"headeer\", \"true\")\n",
    "    .load(\"./data/retail-data/by-day/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingDataFrame.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val purchaseByCustomerPerHour = streamingDataFrame\n",
    "    .selectExpr(\n",
    "        \"CustomerId\",\n",
    "        \"(UnitPrice * Quantity) as total_cost\",\n",
    "        \"InvoiceDate\")\n",
    "    .groupBy(\n",
    "        col(\"CustomerId\"), window(col(\"InvoiceDate\"), \"1 day\"))\n",
    "    .sum(\"total_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseByCustomerPerHour.writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"customer_purchases\")\n",
    "    .outputMode(\"complete\")\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM customer_purchases\n",
    "    ORDER BY 'sum(total_cost)' DESC\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchaseByCustomerPerHour.writeStream\n",
    "    .format(\"console\")\n",
    "    .queryName(\"customer_purchases_2\")\n",
    "    .outputMode(\"complete\")\n",
    "    .start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
