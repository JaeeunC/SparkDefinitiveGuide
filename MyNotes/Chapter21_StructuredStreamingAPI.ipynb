{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 구조적 스트리밍의 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.2 핵심 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.1 트랜스포메이션과 액션\n",
    "+ 트렌스포메이션과 유사하나 증분 처리를 할 수 없는 일부 쿼리 유형은 사용 제약이 있을 수 있음\n",
    "+ 구조적 스트리밍에는 스트림 처리를 시작한 뒤 연속적으로 처리해 결과를 출력하는 한 가지 액션만 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.2 입력 소스\n",
    "+ 스트리밍 방식으로 데이터를 읽을 수 있는 소스\n",
    "    + 아파치 카프카 0.10 버전\n",
    "    + HDFS나 S3 등 분산 파일시스템의 파일(스파크는 디렉터리의 신규 파일을 계속해서 읽음)\n",
    "    + 테스트용 소켓 소스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.3 싱크\n",
    "+ 스트림의 결과를 저장할 목적지\n",
    "    + 아파치 카프카 0.10\n",
    "    + 거의 모든 파일 포맷\n",
    "    + 출력 레코드에 임의 연산을 실행하는 foreach 싱크\n",
    "    + 테스트용 콘솔 싱크\n",
    "    + 디버깅용 콘솔 싱크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.4 출력 모드\n",
    "+ 데이터를 출력하는 방법의 정의\n",
    "    + append: 싱크에 신규 레코드만 추가\n",
    "    + update: 변경 대상 레코드 자체를 갱신\n",
    "    + complete: 전체 출력 내용 재작성 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.5 트리거\n",
    "+ 데이터 출력 시점을 정의\n",
    "+ 기본적으로 마지막 입력 데이터를 처리한 직후에 신규 입력 데이터를 조회해 최단 시간 내에 새로운 처리 결과를 만들어 냄\n",
    "+ 작은 크기의 파일이 여러 개 생실 수 있기 때문에 처리 시간 기반의 트리거도 지원함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2.6 이벤트 시간 처리\n",
    "+ 데이터에 기록되 시간 필드 기준으로 데이터를 처리함을 의미\n",
    "+ 워터마크: 시간 제한을 설정할 수 있는 스트리밍 시스템의 기능으로 늦게 들어온 이벤트를 어디까지 처리할지 시간을 제한할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.3 구조적 스트리밍 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정적인 방식의 데이터셋 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 생성\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark structured streaming example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set('spark.sql.shuffle.partitions', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = spark.read.json(\"../data/activity-data/\")\n",
    "dataSchema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(Arrival_Time,LongType,true),StructField(Creation_Time,LongType,true),StructField(Device,StringType,true),StructField(Index,LongType,true),StructField(Model,StringType,true),StructField(User,StringType,true),StructField(gt,StringType,true),StructField(x,DoubleType,true),StructField(y,DoubleType,true),StructField(z,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "print(dataSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Arrival_Time: long (nullable = true)\n",
      " |-- Creation_Time: long (nullable = true)\n",
      " |-- Device: string (nullable = true)\n",
      " |-- Index: long (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- User: string (nullable = true)\n",
      " |-- gt: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동적인 방식의 데이터셋 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 하나씩 읽는 것을 가정(운영 환경에서는 이렇게 사용하지 말 것)\n",
    "# 데이터 형을 자동으로 추론하는 것은 비추(예제에서는 위에서 읽은 데이터형을 재활용)\n",
    "streaming = spark\\\n",
    "    .readStream\\\n",
    "    .schema(dataSchema)\\\n",
    "    .option('maxFilesPerTrigger', 1)\\\n",
    "    .json(\"../data/activity-data/\")\n",
    "\n",
    "# 트렌스포메이션\n",
    "activityCounts = streaming.groupBy('gt').count()\n",
    "\n",
    "# 결과를 메모리에 저장하도록 메모리 싱크 설정\n",
    "activityQuery = activityCounts\\\n",
    "    .writeStream\\\n",
    "    .queryName('activity_counts')\\\n",
    "    .format('memory')\\\n",
    "    .outputMode('complete')\\\n",
    "    .start()\n",
    "\n",
    "# 실행\n",
    "# activityQuery.awaitTermination() # 쿼리 종료 시 까지 대기함, background에서 실행됨\n",
    "                                   # 운영 애플리케이션에서는 반드시 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7f1ed27cae90>,\n",
       " <pyspark.sql.streaming.StreamingQuery at 0x7f1ed273d9d0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스트림 목록을 확인할 수 있음\n",
    "# UUID가 부여되어 다시 선택할 수 있지만 여기서는 변수에 할당했으므로 변수 사용이 유리함\n",
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|110776|\n",
      "|     stand|102464|\n",
      "|stairsdown| 84283|\n",
      "|      walk|119304|\n",
      "|  stairsup| 94069|\n",
      "|      null| 94034|\n",
      "|      bike| 97177|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|172317|\n",
      "|     stand|159385|\n",
      "|stairsdown|131088|\n",
      "|      walk|185585|\n",
      "|  stairsup|146368|\n",
      "|      null|146263|\n",
      "|      bike|151163|\n",
      "+----------+------+\n",
      "\n",
      "+----------+------+\n",
      "|        gt| count|\n",
      "+----------+------+\n",
      "|       sit|233856|\n",
      "|     stand|216309|\n",
      "|stairsdown|177893|\n",
      "|      walk|251865|\n",
      "|  stairsup|198660|\n",
      "|      null|198494|\n",
      "|      bike|205151|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM activity_counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "activityQuery.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.4 스트림 트랜스포메이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.4.1 선택과 필터링\n",
    "+ 키를 변경하지 않으므로 append 출력 모드를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "simpleTransfrom = streaming.withColumn(\"stairs\", expr(\"gt like '%stairs%'\"))\\\n",
    "    .where(\"stairs\")\\\n",
    "    .where(\"gt is not null\")\\\n",
    "    .select(\"gt\", \"model\", \"arrival_time\", \"creation_time\")\\\n",
    "    .writeStream\\\n",
    "    .queryName(\"simple_transform\")\\\n",
    "    .format(\"memory\")\\\n",
    "    .outputMode(\"append\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.4.2 집계\n",
    "+ 7장 스트림에 적용 가능한 함수 참조\n",
    "+ 원시 컬럼에 대한 집계 외 이벤트 시간 컬럼 지정, 워터마크, 윈도우 처리를 지원함 (22장 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceModelStats = streaming.cube(\"gt\", \"model\").avg()\\\n",
    "    .drop(\"avg(Arrival_time)\")\\\n",
    "    .drop(\"avg(Creation_time)\")\\\n",
    "    .drop(\"avg(Index)\")\\\n",
    "    .writeStream.queryName(\"device_counts\").format(\"memory\")\\\n",
    "    .outputMode(\"complete\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|       sit|  null|-5.15907918915406E-4|2.734365086787862E-4|-1.41574357215395...|\n",
      "|     stand|  null|-3.75961836153627...|4.111774313006432E-4|3.049861196337196E-4|\n",
      "|       sit|nexus4|-5.15907918915406E-4|2.734365086787862E-4|-1.41574357215395...|\n",
      "|     stand|nexus4|-3.75961836153627...|4.111774313006432E-4|3.049861196337196E-4|\n",
      "|      null|  null|-0.00699334693654...|-0.00117077767059...|0.005646005653992309|\n",
      "|      null|  null|0.001510247341501...|-0.00696338577209...|-0.00910733461973...|\n",
      "|      walk|  null|-0.00304135060055069|0.004227462440234609|-6.40891870085253...|\n",
      "|      null|nexus4|-0.00699334693654...|-0.00117077767059...|0.005646005653992309|\n",
      "|      null|nexus4|0.001510247341501...|-0.00696338577209...|-0.00910733461973...|\n",
      "|      bike|  null|  0.0250431807767852|-0.01054190537931...|-0.08249728393481527|\n",
      "|  stairsup|  null|-0.02566381095830...|-0.01156850181701...|-0.10024452219597685|\n",
      "|stairsdown|  null|0.025594402102258416|-0.03847850318554955|  0.1255559483109588|\n",
      "|      bike|nexus4|  0.0250431807767852|-0.01054190537931...|-0.08249728393481527|\n",
      "|      walk|nexus4|-0.00304135060055069|0.004227462440234609|-6.40891870085253...|\n",
      "|stairsdown|nexus4|0.025594402102258416|-0.03847850318554955|  0.1255559483109588|\n",
      "|  stairsup|nexus4|-0.02566381095830...|-0.01156850181701...|-0.10024452219597685|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|       sit|  null|-5.07251451936709...|3.073807798549758E-4|-1.30352888086243...|\n",
      "|     stand|  null|-3.77056051897803...|3.774624836383796...|2.271646020037544E-4|\n",
      "|       sit|nexus4|-5.07251451936709...|3.073807798549758E-4|-1.30352888086243...|\n",
      "|     stand|nexus4|-3.77056051897803...|3.774624836383796...|2.271646020037544E-4|\n",
      "|      null|  null|-0.00770515338670...|-9.86285626979076...|0.003953144322972485|\n",
      "|      null|  null|8.186511643770415E-4|-0.00692948546484...|-0.00897082575848...|\n",
      "|      walk|  null|-0.00420626560819...|0.003293984745767952|3.655688175542223E-5|\n",
      "|      null|nexus4|-0.00770515338670...|-9.86285626979076...|0.003953144322972485|\n",
      "|      null|nexus4|8.186511643770415E-4|-0.00692948546484...|-0.00897082575848...|\n",
      "|      bike|  null|0.023019073465984013|-0.00951191658301343|-0.08299550917143556|\n",
      "|  stairsup|  null|-0.02626317293005844|-0.00937862856730...|-0.09842125977710875|\n",
      "|stairsdown|  null| 0.02526738413068417|-0.04071558758727275| 0.12624512404546454|\n",
      "|      bike|nexus4|0.023019073465984013|-0.00951191658301343|-0.08299550917143556|\n",
      "|      walk|nexus4|-0.00420626560819...|0.003293984745767952|3.655688175542223E-5|\n",
      "|stairsdown|nexus4| 0.02526738413068417|-0.04071558758727275| 0.12624512404546454|\n",
      "|  stairsup|nexus4|-0.02626317293005844|-0.00937862856730...|-0.09842125977710875|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|        gt| model|              avg(x)|              avg(y)|              avg(z)|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "|       sit|  null|-4.99368126296369...|2.512465019316055...|-1.78368257768059E-4|\n",
      "|     stand|  null|-3.53324114394987...|4.068373706090746...|2.175775439366989E-4|\n",
      "|       sit|nexus4|-4.99368126296369...|2.512465019316055...|-1.78368257768059E-4|\n",
      "|     stand|nexus4|-3.53324114394987...|4.068373706090746...|2.175775439366989E-4|\n",
      "|      null|  null|-0.00758325702758...|-6.60492931776380...|0.004959665818381161|\n",
      "|      null|  null|7.675859038081611E-4|-0.00643620860750...|-0.00896069060137...|\n",
      "|      walk|  null|-0.00398943559989...|0.003045739166713...|-3.53792977582499...|\n",
      "|      null|nexus4|-0.00758325702758...|-6.60492931776380...|0.004959665818381161|\n",
      "|      null|nexus4|7.675859038081611E-4|-0.00643620860750...|-0.00896069060137...|\n",
      "|      bike|  null|0.023272363877139417|-0.00966707396580...| -0.0824919414697989|\n",
      "|  stairsup|  null|-0.02657683302243...|-0.00862140571595...|-0.09868513795745312|\n",
      "|stairsdown|  null| 0.02442416784709569|-0.03724819948800649| 0.12512176269372702|\n",
      "|      bike|nexus4|0.023272363877139417|-0.00966707396580...| -0.0824919414697989|\n",
      "|      walk|nexus4|-0.00398943559989...|0.003045739166713...|-3.53792977582499...|\n",
      "|stairsdown|nexus4| 0.02442416784709569|-0.03724819948800649| 0.12512176269372702|\n",
      "|  stairsup|nexus4|-0.02657683302243...|-0.00862140571595...|-0.09868513795745312|\n",
      "+----------+------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(3):\n",
    "    spark.sql(\"SELECT * FROM device_counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceModelStats.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.5 입력과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 소스와 싱크\n",
    "+ 스트리밍에서 파일 소스/싱크와 정적 파일 소스를 사용할 때 유일한 차이점은 트리거 시 읽을 파일 수를 결정할 수 있다는 점임(maxFilesPerTrigger 옵션)\n",
    "+ 입력 디텍더리에 원자적으로 추가되어하며, 그렇지 않으면 파일의 일부분만 처리됨\n",
    "+ 외부 디렉터리에 파일을 완전히 기록한 후 입력 디텍터리로 옮겨야 함(아마존 S3에서는 완전히 기록된 객체만 보임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카프카 소스와 싱크\n",
    "+ 카프카는 분산형 버퍼로 생각할 수 있음\n",
    "+ 순서를 바꿀 수 없는 레코드로 구성되며 레코드의 위치를 오프셋이라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.5.2 카프카 소스에서 메시지 읽기\n",
    "+ 아래 옵션 중 하나를 선택\n",
    "    + assign : 토픽뿐만 아니라 읽으려는 파티션까지 세밀하게 지정하는 옵션, ex) {\"topicA\":[0, 1], \"topicB\":[2, 4]}\n",
    "    + subscribe : 토픽 목록턴을 지정해 여러 토픽을 구독\n",
    "    + subscribePattern : 토픽 패턴을 지정해 여러 토픽을 구독\n",
    "+ 카프카 서비스에 접속할 수 있도록 kafka.bootstrap.servers 값을 지정\n",
    "+ 기타\n",
    "    + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
